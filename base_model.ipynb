{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "base model",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mingrui-liu/Hyperpigmentation-autograde/blob/main/base_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXXKBhRLM9Ss"
      },
      "source": [
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.optimizers import SGD,Adam,RMSprop,Nadam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd8bXs_AfWjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b962dbf-b6e2-4faf-a9b3-d4ba988521e7"
      },
      "source": [
        "# connect to your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvxfQGdKurze"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 64\n",
        "IMG_SIZE = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsnrwBvgfr_K"
      },
      "source": [
        "#Create image tf dataset from directory \n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "  image = tf.io.read_file(path)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "  return image\n",
        "\n",
        "all_image_paths_1 = sorted(glob.glob(\"/content/drive/My Drive/Unilever/image_test/*.jpg\"))\n",
        "all_image_paths_2 = sorted(glob.glob(\"/content/drive/My Drive/Unilever/Additional_Images/*.jpg\"))\n",
        "\n",
        "# read the excel file\n",
        "MHPgrades = pd.read_excel(\"/content/drive/My Drive/Unilever/MHPgrades.xlsx\",header = 0)\n",
        "MHPgrades2 = pd.read_excel(\"/content/drive/My Drive/Unilever/SKN-APP-0452-MHPgrades.xlsx\",header = 1)\n",
        "\n",
        "MHPgrades2 = MHPgrades2.dropna(axis = 0)\n",
        "MHPgrades2 = MHPgrades2.melt(id_vars=[\"Subject No.\", \"Side of Face\"], \n",
        "        var_name=\"VISIT\", \n",
        "        value_name=\"Mottled hyperpigmentation\").sort_values(by = ['Subject No.','Side of Face'])\n",
        "\n",
        "grade1 = MHPgrades[\"Mottled hyperpigmentation\"]\n",
        "\n",
        "#Manipulate excel file\n",
        "MHPgrades2.loc[MHPgrades2['VISIT'] == 'Baseline' , 'VISIT'] = '00'\n",
        "MHPgrades2.loc[MHPgrades2['VISIT'] == 'Week 4' , 'VISIT'] = '04'\n",
        "MHPgrades2.loc[MHPgrades2['VISIT'] == 'Week 8' , 'VISIT'] = '08'\n",
        "MHPgrades2.loc[MHPgrades2['VISIT'] == 'Week 12' , 'VISIT'] = '12'\n",
        "MHPgrades2.loc[MHPgrades2['VISIT'] == 'Week 16' , 'VISIT'] = '16'\n",
        "MHPgrades2.loc[MHPgrades2['VISIT'] == 'Week 17' , 'VISIT'] = '17'\n",
        "\n",
        "MHPgrades2.loc[MHPgrades2['Side of Face'] == 'Left' , 'Side of Face'] = 'L'\n",
        "MHPgrades2.loc[MHPgrades2['Side of Face'] == 'Right' , 'Side of Face'] = 'R'\n",
        "\n",
        "#match grade and images and make valid pair\n",
        "valid_path = []\n",
        "valid_label = []\n",
        "for index, row in MHPgrades2.iterrows():\n",
        "    id = str(row['Subject No.'] )\n",
        "    id = id.zfill(4)\n",
        "\n",
        "    side = row['Side of Face']\n",
        "   \n",
        "    visit = str(row['VISIT'])\n",
        "\n",
        "    grade = row['Mottled hyperpigmentation']\n",
        "  \n",
        "\n",
        "\n",
        "    output = [path for path in all_image_paths_2 if path.startswith('/content/drive/My Drive/Unilever/Additional_Images/P' + id + '_FACE_' + side + '_S00_VCR_S2_V00D00W' + visit)] \n",
        "    if len(output)>0:\n",
        "      valid_path.append(output[0])\n",
        "      valid_label.append(grade)\n",
        "\n",
        "all_image_paths = all_image_paths_1 + valid_path\n",
        "all_image_labels = list(grade1) +  valid_label\n",
        "print(len(all_image_labels ))\n",
        "print(len(all_image_paths))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKLVBym0_AUs"
      },
      "source": [
        "##Create label and zip dataset\n",
        "all_label = []\n",
        "for grade in all_image_labels:\n",
        "  if grade < 2.0:\n",
        "    label = 1.5\n",
        "  elif grade > 4.0:\n",
        "    label = 4.5\n",
        "  else:\n",
        "    label = grade\n",
        "  all_label.append(label)\n",
        "\n",
        "label_to_index = dict((name, index) for index, name in enumerate(sorted(set(all_label))))\n",
        "all_labels = [label_to_index[grade] for grade in all_label]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(all_image_paths, all_labels) \n",
        "\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(train_paths)\n",
        "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "DATASET_SIZE = len(image_ds)\n",
        "label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(train_labels, tf.float32))\n",
        "\n",
        "# a dataset that returns images and labels\n",
        "image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS5fLR0Ql9Iv"
      },
      "source": [
        "using generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1HadDQ2uXvg"
      },
      "source": [
        "\n",
        "# here's our final training dataset\n",
        "train_ds = image_label_ds.cache()\n",
        "train_ds = train_ds.shuffle(len(train_ds))\n",
        "train_ds = train_ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# let's make a test dataset as well\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(test_paths)\n",
        "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(test_labels, tf.float32))\n",
        "image_label_ds_test = tf.data.Dataset.zip((image_ds, label_ds))\n",
        "test_ds = image_label_ds_test.cache().batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf520FCDI8AS"
      },
      "source": [
        "### base model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJD_66N4Gj-r"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(16, (3, 3), activation='relu', \n",
        "                        input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "model.add(layers.MaxPooling2D())\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(7, activation='softmax'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_ds, validation_data=test_ds, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFzzVYcJBp-I"
      },
      "source": [
        "#### Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luGAWZxYAlev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c76d13-0a54-46d2-ee40-564c8d2d446e"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "base_model = ResNet50(include_top = False, weights = 'imagenet', \n",
        "                         input_shape = (IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "\n",
        "for layer in base_model.layers[:20]:\n",
        "  layer.trainable = False\n",
        "\n",
        "drop_out = tf.keras.layers.Dropout(.2, input_shape =(24, 16, 16,2048))\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(7, activation='softmax')\n",
        "\n",
        "# build a new model reusing the pretrained base\n",
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  drop_out,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# This function keeps the initial learning rate for the first ten epochs\n",
        "# and decreases it exponentially after that.\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 10:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "#  no rescale  no augmentation ,trainable = true\n",
        "history = model.fit(train_ds,\n",
        "      epochs=50,\n",
        "      callbacks=[callback],\n",
        "      validation_data = test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRPh2iPAI4XD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0dADPI4-uO0"
      },
      "source": [
        "def plot(history):\n",
        "  \n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.plot(history.history['accuracy'], label='accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.plot(history.history['loss'][7:], label='loss')\n",
        "    plt.plot(history.history['val_loss'][7:], label = 'val_loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZxFsmPvGrM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24d4051-7c70-4ad9-9a81-f4c187359c1e"
      },
      "source": [
        "# build a new model reusing the pretrained base\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "base_model = ResNet50(include_top = False, weights = 'imagenet', \n",
        "                         input_shape = (IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "for layer in base_model.layers[:20]:\n",
        "  layer.trainable = False\n",
        "\n",
        "drop_out = tf.keras.layers.Dropout(.4, input_shape =(24, 16, 16,2048))\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(7, activation='softmax')\n",
        "\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  drop_out,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-6)\n",
        "\n",
        "model2.compile(optimizer= opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history2 = model2.fit(train_ds,\n",
        "      epochs = 100,\n",
        "      validation_data = test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "29/29 [==============================] - 18s 634ms/step - loss: 2.4760 - accuracy: 0.1171 - val_loss: 2.8499 - val_accuracy: 0.1398\n",
            "Epoch 2/50\n",
            "29/29 [==============================] - 18s 613ms/step - loss: 2.3190 - accuracy: 0.1199 - val_loss: 2.6546 - val_accuracy: 0.1398\n",
            "Epoch 3/50\n",
            "29/29 [==============================] - 17s 600ms/step - loss: 2.1883 - accuracy: 0.1310 - val_loss: 2.4665 - val_accuracy: 0.1464\n",
            "Epoch 4/50\n",
            "29/29 [==============================] - 17s 594ms/step - loss: 2.0711 - accuracy: 0.1559 - val_loss: 2.2877 - val_accuracy: 0.1564\n",
            "Epoch 5/50\n",
            "29/29 [==============================] - 17s 596ms/step - loss: 1.9695 - accuracy: 0.1881 - val_loss: 2.1287 - val_accuracy: 0.1697\n",
            "Epoch 6/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 1.8767 - accuracy: 0.2175 - val_loss: 2.0100 - val_accuracy: 0.1797\n",
            "Epoch 7/50\n",
            "29/29 [==============================] - 17s 602ms/step - loss: 1.7880 - accuracy: 0.2664 - val_loss: 1.9150 - val_accuracy: 0.2196\n",
            "Epoch 8/50\n",
            "29/29 [==============================] - 17s 601ms/step - loss: 1.7116 - accuracy: 0.3102 - val_loss: 1.8326 - val_accuracy: 0.2596\n",
            "Epoch 9/50\n",
            "29/29 [==============================] - 17s 597ms/step - loss: 1.6493 - accuracy: 0.3424 - val_loss: 1.7671 - val_accuracy: 0.2696\n",
            "Epoch 10/50\n",
            "29/29 [==============================] - 17s 597ms/step - loss: 1.5765 - accuracy: 0.4029 - val_loss: 1.7134 - val_accuracy: 0.3178\n",
            "Epoch 11/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 1.5109 - accuracy: 0.4428 - val_loss: 1.6718 - val_accuracy: 0.3527\n",
            "Epoch 12/50\n",
            "29/29 [==============================] - 17s 600ms/step - loss: 1.4656 - accuracy: 0.4767 - val_loss: 1.6360 - val_accuracy: 0.3727\n",
            "Epoch 13/50\n",
            "29/29 [==============================] - 17s 600ms/step - loss: 1.4090 - accuracy: 0.5078 - val_loss: 1.6083 - val_accuracy: 0.3744\n",
            "Epoch 14/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 1.3706 - accuracy: 0.5233 - val_loss: 1.5846 - val_accuracy: 0.3977\n",
            "Epoch 15/50\n",
            "29/29 [==============================] - 17s 598ms/step - loss: 1.3350 - accuracy: 0.5533 - val_loss: 1.5640 - val_accuracy: 0.4093\n",
            "Epoch 16/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 1.3103 - accuracy: 0.5683 - val_loss: 1.5470 - val_accuracy: 0.4126\n",
            "Epoch 17/50\n",
            "29/29 [==============================] - 17s 596ms/step - loss: 1.2676 - accuracy: 0.5777 - val_loss: 1.5347 - val_accuracy: 0.4126\n",
            "Epoch 18/50\n",
            "29/29 [==============================] - 17s 597ms/step - loss: 1.2333 - accuracy: 0.6060 - val_loss: 1.5208 - val_accuracy: 0.4193\n",
            "Epoch 19/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 1.2024 - accuracy: 0.6121 - val_loss: 1.5079 - val_accuracy: 0.4226\n",
            "Epoch 20/50\n",
            "29/29 [==============================] - 17s 596ms/step - loss: 1.1754 - accuracy: 0.6204 - val_loss: 1.4966 - val_accuracy: 0.4226\n",
            "Epoch 21/50\n",
            "29/29 [==============================] - 17s 597ms/step - loss: 1.1385 - accuracy: 0.6493 - val_loss: 1.4863 - val_accuracy: 0.4293\n",
            "Epoch 22/50\n",
            "29/29 [==============================] - 17s 596ms/step - loss: 1.1120 - accuracy: 0.6604 - val_loss: 1.4773 - val_accuracy: 0.4359\n",
            "Epoch 23/50\n",
            "29/29 [==============================] - 17s 598ms/step - loss: 1.0908 - accuracy: 0.6726 - val_loss: 1.4690 - val_accuracy: 0.4409\n",
            "Epoch 24/50\n",
            "29/29 [==============================] - 17s 598ms/step - loss: 1.0541 - accuracy: 0.6976 - val_loss: 1.4612 - val_accuracy: 0.4409\n",
            "Epoch 25/50\n",
            "29/29 [==============================] - 17s 598ms/step - loss: 1.0374 - accuracy: 0.7037 - val_loss: 1.4535 - val_accuracy: 0.4393\n",
            "Epoch 26/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 1.0081 - accuracy: 0.7231 - val_loss: 1.4462 - val_accuracy: 0.4393\n",
            "Epoch 27/50\n",
            "29/29 [==============================] - 17s 598ms/step - loss: 0.9953 - accuracy: 0.7231 - val_loss: 1.4395 - val_accuracy: 0.4409\n",
            "Epoch 28/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 0.9696 - accuracy: 0.7531 - val_loss: 1.4323 - val_accuracy: 0.4476\n",
            "Epoch 29/50\n",
            "29/29 [==============================] - 17s 598ms/step - loss: 0.9519 - accuracy: 0.7442 - val_loss: 1.4264 - val_accuracy: 0.4493\n",
            "Epoch 30/50\n",
            "29/29 [==============================] - 17s 598ms/step - loss: 0.9193 - accuracy: 0.7825 - val_loss: 1.4196 - val_accuracy: 0.4542\n",
            "Epoch 31/50\n",
            "29/29 [==============================] - 17s 600ms/step - loss: 0.8977 - accuracy: 0.7875 - val_loss: 1.4142 - val_accuracy: 0.4559\n",
            "Epoch 32/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 0.8799 - accuracy: 0.7902 - val_loss: 1.4091 - val_accuracy: 0.4576\n",
            "Epoch 33/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 0.8763 - accuracy: 0.8036 - val_loss: 1.4049 - val_accuracy: 0.4592\n",
            "Epoch 34/50\n",
            "29/29 [==============================] - 17s 598ms/step - loss: 0.8412 - accuracy: 0.8224 - val_loss: 1.4004 - val_accuracy: 0.4559\n",
            "Epoch 35/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 0.8349 - accuracy: 0.8102 - val_loss: 1.3955 - val_accuracy: 0.4576\n",
            "Epoch 36/50\n",
            "29/29 [==============================] - 17s 598ms/step - loss: 0.8155 - accuracy: 0.8257 - val_loss: 1.3919 - val_accuracy: 0.4626\n",
            "Epoch 37/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 0.7838 - accuracy: 0.8446 - val_loss: 1.3883 - val_accuracy: 0.4642\n",
            "Epoch 38/50\n",
            "29/29 [==============================] - 17s 598ms/step - loss: 0.7679 - accuracy: 0.8529 - val_loss: 1.3848 - val_accuracy: 0.4609\n",
            "Epoch 39/50\n",
            "29/29 [==============================] - 17s 598ms/step - loss: 0.7528 - accuracy: 0.8546 - val_loss: 1.3814 - val_accuracy: 0.4642\n",
            "Epoch 40/50\n",
            "29/29 [==============================] - 17s 596ms/step - loss: 0.7337 - accuracy: 0.8713 - val_loss: 1.3775 - val_accuracy: 0.4642\n",
            "Epoch 41/50\n",
            "29/29 [==============================] - 17s 596ms/step - loss: 0.7160 - accuracy: 0.8790 - val_loss: 1.3742 - val_accuracy: 0.4642\n",
            "Epoch 42/50\n",
            "29/29 [==============================] - 17s 597ms/step - loss: 0.6926 - accuracy: 0.8851 - val_loss: 1.3713 - val_accuracy: 0.4659\n",
            "Epoch 43/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 0.6801 - accuracy: 0.8885 - val_loss: 1.3682 - val_accuracy: 0.4659\n",
            "Epoch 44/50\n",
            "29/29 [==============================] - 17s 598ms/step - loss: 0.6659 - accuracy: 0.8968 - val_loss: 1.3658 - val_accuracy: 0.4642\n",
            "Epoch 45/50\n",
            "29/29 [==============================] - 17s 598ms/step - loss: 0.6517 - accuracy: 0.8968 - val_loss: 1.3631 - val_accuracy: 0.4659\n",
            "Epoch 46/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 0.6273 - accuracy: 0.9134 - val_loss: 1.3615 - val_accuracy: 0.4659\n",
            "Epoch 47/50\n",
            "29/29 [==============================] - 17s 600ms/step - loss: 0.6245 - accuracy: 0.9118 - val_loss: 1.3586 - val_accuracy: 0.4626\n",
            "Epoch 48/50\n",
            "29/29 [==============================] - 17s 597ms/step - loss: 0.6043 - accuracy: 0.9201 - val_loss: 1.3565 - val_accuracy: 0.4676\n",
            "Epoch 49/50\n",
            "29/29 [==============================] - 17s 597ms/step - loss: 0.5891 - accuracy: 0.9290 - val_loss: 1.3544 - val_accuracy: 0.4692\n",
            "Epoch 50/50\n",
            "29/29 [==============================] - 17s 599ms/step - loss: 0.5682 - accuracy: 0.9334 - val_loss: 1.3514 - val_accuracy: 0.4692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcfba1af940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiwNfFJtcXYj"
      },
      "source": [
        "plot(history2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}